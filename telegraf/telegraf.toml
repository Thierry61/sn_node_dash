# Interesting links:
# - https://docs.influxdata.com/telegraf/v1.21/administration/configuration/#agent-configuration
# - https://github.com/influxdata/telegraf/tree/master/plugins/inputs/tail
# - https://github.com/influxdata/telegraf/tree/master/plugins/parsers/grok
# - https://github.com/vjeantet/grok/blob/master/patterns/grok-patterns
# - https://github.com/influxdata/telegraf/blob/master/plugins/parsers/grok/influx_patterns.go
# - https://grokdebug.herokuapp.com/

[agent]
  omit_hostname = true

[global_tags]
  node = "mynode"

[[inputs.tail]]
  files = ["/logs/sn_node.log.*", "/logs/sn_node.log"]
  from_beginning = true
  # watch_method = "inotify"
  # max_undelivered_lines = 1000
  # character_encoding = ""
  data_format = "grok"
  path_tag = ""
  grok_patterns = ["%{ERROR_LINE}", "%{HEADER_LINE}"]
  grok_custom_patterns = '''
    # General structure: header line + continuation lines
    HEADER_LINE %{LOGLEVEL} %{TIMESTAMP_SN:timestamp:ts-"2006-01-02T15:04:05.000000Z"} \[%{NOTSPACE}\]:\s+➤ %{CONTINUATION}

    # Timesatmp structure
    TIMESTAMP_SN %{YEAR}-%{MONTHNUM}-%{MONTHDAY}T%{HOUR}:%{MINUTE}:\d\d\.\d\d\d\d\d\dZ

    # Types of lines analyzed, the last one is a fallback to ignore other lines
    CONTINUATION (%{ELDER}|%{STATE}|%{RESOURCE}|%{CHUNKS}|%{AGE}|%{USED_SPACE}|%{MAX_CAPACITY}|%{GREEDYDATA:remaining:drop})

    # sn_node resource usage (memory, cpu, disk)
    RESOURCE %{GREEDYDATA}➤ Node resource usage: Process { memory: %{NONNEGINT:memory:int}, virtual_memory: %{NONNEGINT:virtual_memory:int}, cpu_usage: %{NUMBER:cpu_usage:float}, disk_usage: DiskUsage { total_written_bytes: %{NONNEGINT:total_written_bytes:int}, written_bytes: %{NONNEGINT:written_bytes:int}, total_read_bytes: %{NONNEGINT:total_read_bytes:int}, read_bytes: %{NONNEGINT:read_bytes:int} } } prefix="%{PREFIX:prefix:string}"

    # Node age
    AGE Our AGE: %{NONNEGINT:age:int}

    # Used space and max capacity
    USED_SPACE %{GREEDYDATA}➤ Used space: %{NONNEGINT:used_space:int}
    MAX_CAPACITY %{GREEDYDATA}➤ Max capacity: %{NONNEGINT:max_capacity:int}

    # Node states. Note that:
    # - "Genesis" overiddes a preceeding "Elder" state (a few µs later)
    # - "Joined", "Genesis" and "Demoted" are all adults
    # TODO: "Demoted"
    STATE %{NODE_ID:node_id:string} %{WORD:state:string} (%{BOOTSTRAPPING}|%{JOINING}|%{JOINED}|%{GENESIS})
    BOOTSTRAPPING a new node\.
    JOINING as a new node.*
    JOINED the network!
    GENESIS node started!.*

    # Different field name (state2) because if state is reused this pattern is never matched
    ELDER %{GREEDYDATA}➤ PromotedTo%{WORD_END:state2:string}.*

    # Chunk management by adults
    # Here also different field names are needed (chunk + chunk2)
    # TODO: "Removing" and "Already exists"
    CHUNKS %{GREEDYDATA}➤ (%{STORED}|%{GETTING})
    STORED %{WORD_BEGIN:chunk:string}NewChunk
    GETTING %{WORD:chunk2:string} chunk ChunkAddress.*

    # Error line. Not a chunk but managed the same way (events displayed in an histogram)
    ERROR_LINE %{ERROR:chunk3:string} %{TIMESTAMP_SN:timestamp:ts-"2006-01-02T15:04:05.000000Z"} %{GREEDYDATA:remaining:drop}
    ERROR ERROR

    # Internal patterns
    WORD_END \w+\b
    WORD_BEGIN \b\w+
    NODE_ID [0-9a-fA-F]{6}\.\.
    PREFIX \([01]*\)
'''

  ## multiline parser/codec
  ## https://www.elastic.co/guide/en/logstash/2.4/plugins-filters-multiline.html
  [inputs.tail.multiline]
    pattern = '^\s+➤'
    # match_which_line = "previous"
    # invert_match = false
    # timeout = 5s

# Rename the fields that we were forced to add to make some patterns work (state2, chunk2)
[[processors.rename]]
  [[processors.rename.replace]]
    field = "state2"
    dest = "state"
  [[processors.rename.replace]]
    field = "chunk2"
    dest = "chunk"
  [[processors.rename.replace]]
    field = "chunk3"
    dest = "chunk"

[[outputs.influxdb_v2]]
  urls = ["http://influxdb:8086"]
  token = "GYQamYfyV46350EY0EBw7bVPUzVQGXz6qUEGkV3BFdchJJ0IPOn1xTpV-HkhJV3NaJ-Jb1MGi9w_Zk9gmcaL1w=="
  organization = "MyOrg"
  bucket = "SN"
  # bucket_tag = ""
  # exclude_bucket_tag = false
  # timeout = "5s"
  # http_headers = {"X-Special-Header" = "Special-Value"}
  # http_proxy = "http://corporate.proxy:3128"
  # user_agent = "telegraf"
  # content_encoding = "gzip"
  # influx_uint_support = false
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  # insecure_skip_verify = false

# Uncomment for testing (and comment out [[outputs.influxdb_v2]])
# This method is better than adding --test argument to telegraf because the latter doesn't display all metrics
#[[outputs.file]]
#  files = ["stdout"]